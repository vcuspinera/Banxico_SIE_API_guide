mutate(sentiment=(Positive-Negative), method='FED', Date=date[j])
s_score_b[[j]] <- tidy_MPR %>%
mutate(nwords = n()) %>%
inner_join(get_sentiments('bing'), by="word") %>%
add_count(sentiment) %>%
mutate(n = n/nwords) %>%
select(sentiment, n) %>%
distinct(sentiment, .keep_all = TRUE) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment=(positive-negative), method='Bing et al.', Date=date[j])
s_score_a[[j]] <- tidy_MPR %>%
inner_join(get_sentiments('afinn'), by="word") %>%
summarise(sentiment = sum(value)/n()) %>%
mutate(method = "AFINN", Date = date[j])
}
files
files
# Dates for downloaded files
files <- list.files(pattern = "^mpr")
date  <- as.Date(substr(files,5,14))
mths  <- month.abb[month(date)]
yrs   <- year(date)
# Dates for downloaded files
files <- list.files(pattern = "^mpr")
date  <- as.Date(substr(files,5,14))
mths  <- month.abb[month(date)]
yrs   <- year(date)
files
# Dates for downloaded files
files <- list.files(pattern = "^mpr")
date  <- as.Date(substr(files,5,14))
mths  <- month.abb[month(date)]
yrs   <- year(date)
files
date
text_to_frame = function(pdf_file) {
date  <- as.Date(substr(pdf_file,5,14))
mths  <- month.abb[month(date)]
yrs   <- year(date)
MPR <- suppressMessages(pdf_text(pdf_file))
MPR <- gsub("\r\n"," ",MPR)
MPR <- gsub("\t"," ",MPR)
# MPR <- stringi::stri_escape_unicode(MPR)
MPR <- stri_trans_general(MPR, "latin-ascii")
MPR <- iconv(MPR, "UTF-8", "ASCII", sub = " ")
MPR <- gsub("[[:digit:]]+"," ",MPR)
# MPR <- gsub("[[:punct:]]+"," ",MPR)
MPR <- gsub("[[:space:]]+"," ",MPR)
MPR <- tolower(trimws(MPR))
MPR <- gsub("monetary policy report"," ",MPR)
MPR <- gsub("onetary policy report"," ",MPR)
MPR <- gsub("netary policy report"," ",MPR)
MPR <- gsub("m o n e t a r y p o l i c y r e p o r t","",MPR)
MPR <- gsub("r e p o r t o n m o n e t a r y p o l i c y","",MPR)
MPR <- gsub("bank of canada"," ",MPR)
MPR <- gsub("b a n k o f c a n a d a","",MPR)
MPR <- gsub("[[:space:]]+"," ",MPR)
MPR <- gsub("file information for internal use only"," ",MPR)
MPR <- trimws(MPR)
MPR_add <- tibble(page=1:length(MPR),
document=pdf_file,
year=year(date),
month=mths,
text=MPR)
gg <- MPR_add$text
lm <- tolower(month.name[month(date)])
cm <- paste0("^", lm)
for (l in 1:2) {
gg <- trimws(gsub("^global economy", "", gg))
gg <- trimws(gsub("^canadian economy", "", gg))
gg <- trimws(gsub("^appendix", "", gg))
gg <- trimws(gsub("^update", "", gg))
gg <- trimws(gsub("^risks to the inflation outlook", "", gg))
gg <- trimws(gsub("^reassessment of canadian potential output growth", "", gg))
gg <- trimws(gsub(cm, "", gg))
gg <- trimws(gsub(trimws(gsub("", " ", lm)), "", gg))
gg <- trimws(gsub("^chart", "", gg))
gg <- trimws(gsub("^box", "", gg))
gg <- trimws(gsub("^table", "", gg))
}
gg <- trimws(gsub("bankofcanada ca", "", gg))
wr <- which(word(gg) == "bibliography")
if (length(wr) < 1) wr <- which(word(gg) == "references")
MPR_add$text <- gg
if (length(wr) > 0) MPR_add <- MPR_add[1:(wr-1),]
MPR_add <- MPR_add %>%
filter(word(text, 1) != "") %>%
filter(word(text, 1) != "contents") %>%
filter(word(text, 5, 6) != "sixtieth anniversary") %>%
filter(word(text, 1, 3) != "the silver dollar") %>%
filter(word(text, 2, 3) != "sterling silver") %>%
filter(word(text, 2, 3) != "gold coin") %>%
filter(word(text, 1, 2) != "gold coin") %>%
filter(word(text, 1, 3) != "library of parliament") %>%
filter(word(text, 1, 4) != "this is a report") %>%
filter(word(text, 1, 5) != "this text is a commentary") %>%
filter(word(text, 1, 5) != "canada s inflation control strategy")
return(MPR_add)
}
# Dates for downloaded files
files <- list.files(pattern = "^mpr")
date  <- as.Date(substr(files,5,14))
mths  <- month.abb[month(date)]
yrs   <- year(date)
files
date
mths
yrs
# Dates for downloaded files
files <- list.files(pattern = "^mpr")
date  <- as.Date(substr(files,5,14))
mths  <- month.abb[month(date)]
yrs   <- year(date)
files
date
mths
yrs
date
# Dates for downloaded files
files <- list.files(pattern = "^mpr")
date  <- as.Date(substr(files,5,14))
mths  <- month.abb[month(date)]
yrs   <- year(date)
files
date
mths
yrs
date
# Dates for downloaded files
files <- list.files(pattern = "^mpr")
date  <- as.Date(substr(files,5,14))
mths  <- month.abb[month(date)]
yrs   <- year(date)
files
date
mths
yrs
date
Sdict
# Dates for downloaded files
files <- list.files(pattern = "^mpr")
date  <- as.Date(substr(files,5,14))
mths  <- month.abb[month(date)]
yrs   <- year(date)
files
date
mths
yrs
date
text_to_frame
# Dates for downloaded files
files <- list.files(pattern = "^mpr")
date  <- as.Date(substr(files,5,14))
mths  <- month.abb[month(date)]
yrs   <- year(date)
files
date
mths
yrs
date
# Dates for downloaded files
files <- list.files(pattern = "^mpr")
date  <- as.Date(substr(files,5,14))
mths  <- month.abb[month(date)]
yrs   <- year(date)
files
date
mths
yrs
date
s_score_fed <- list()
s_score_a   <- list()
s_score_b   <- list()
pts     <- list()
igram   <- list()
s_score_fed
pts
# Dates for downloaded files
files <- list.files(pattern = "^mpr")
date  <- as.Date(substr(files,5,14))
mths  <- month.abb[month(date)]
yrs   <- year(date)
s_score_fed <- list()
s_score_a   <- list()
s_score_b   <- list()
pts     <- list()
igram   <- list()
for(j in 1:length(files)) {
MPR <- text_to_frame(files[[j]]) # %>%
# mmutate(text = gsub("[[:punct:]]+", " ", text))
# Unnest tokens to single words
tidy_MPR <- MPR %>%
unnest_tokens(word, text) %>%
anti_join(stop_words, by="word")
# Count 'inflation'
igram[[j]] <- tidy_MPR %>%
summarise(pi = 100*sum(word == "inflation")/n()) %>%
mutate(Date = date[j])
# Popular word plots
pts[[j]] <- tidy_MPR %>%
mutate(word = wordStem(word)) %>%
count(word, sort=TRUE) %>%
mutate(proportion = n/sum(n)) %>%
filter(proportion > 0.01) %>%     # More than 1% of the words
mutate(word = reorder(word,proportion)) %>%
ggplot(aes(word,proportion)) +
geom_col(aes(fill=word), show.legend = FALSE) +
theme_minimal() +
coord_flip() +
theme(plot.title = element_text(size=10)) +
labs(title=paste0(mths[j], " ", yrs[j], ": count/total_words"), x="", y="")
# Sentiment scores
s_score_fed[[j]] <- tidy_MPR %>%
mutate(nwords = n()) %>%
inner_join(Sdict, by="word") %>%
add_count(Mood) %>%
mutate(n = n/nwords) %>%
select(Mood, n) %>%
distinct(Mood, .keep_all = TRUE) %>%
pivot_wider(names_from = Mood, values_from = n, values_fill = 0) %>%
mutate(sentiment=(Positive-Negative), method='FED', Date=date[j])
s_score_b[[j]] <- tidy_MPR %>%
mutate(nwords = n()) %>%
inner_join(get_sentiments('bing'), by="word") %>%
add_count(sentiment) %>%
mutate(n = n/nwords) %>%
select(sentiment, n) %>%
distinct(sentiment, .keep_all = TRUE) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment=(positive-negative), method='Bing et al.', Date=date[j])
s_score_a[[j]] <- tidy_MPR %>%
inner_join(get_sentiments('afinn'), by="word") %>%
summarise(sentiment = sum(value)/n()) %>%
mutate(method = "AFINN", Date = date[j])
}
# Dates for downloaded files
files <- list.files(pattern = "^mpr")
date  <- as.Date(substr(files,5,14))
mths  <- month.abb[month(date)]
yrs   <- year(date)
s_score_fed <- list()
s_score_a   <- list()
s_score_b   <- list()
pts     <- list()
igram   <- list()
for(j in 1:length(files)) {
MPR <- text_to_frame(files[[j]])  %>%
mmutate(text = gsub("[[:punct:]]+", " ", text))
# Unnest tokens to single words
tidy_MPR <- MPR %>%
unnest_tokens(word, text) %>%
anti_join(stop_words, by="word")
# Count 'inflation'
igram[[j]] <- tidy_MPR %>%
summarise(pi = 100*sum(word == "inflation")/n()) %>%
mutate(Date = date[j])
# Popular word plots
pts[[j]] <- tidy_MPR %>%
mutate(word = wordStem(word)) %>%
count(word, sort=TRUE) %>%
mutate(proportion = n/sum(n)) %>%
filter(proportion > 0.01) %>%     # More than 1% of the words
mutate(word = reorder(word,proportion)) %>%
ggplot(aes(word,proportion)) +
geom_col(aes(fill=word), show.legend = FALSE) +
theme_minimal() +
coord_flip() +
theme(plot.title = element_text(size=10)) +
labs(title=paste0(mths[j], " ", yrs[j], ": count/total_words"), x="", y="")
# Sentiment scores
s_score_fed[[j]] <- tidy_MPR %>%
mutate(nwords = n()) %>%
inner_join(Sdict, by="word") %>%
add_count(Mood) %>%
mutate(n = n/nwords) %>%
select(Mood, n) %>%
distinct(Mood, .keep_all = TRUE) %>%
pivot_wider(names_from = Mood, values_from = n, values_fill = 0) %>%
mutate(sentiment=(Positive-Negative), method='FED', Date=date[j])
s_score_b[[j]] <- tidy_MPR %>%
mutate(nwords = n()) %>%
inner_join(get_sentiments('bing'), by="word") %>%
add_count(sentiment) %>%
mutate(n = n/nwords) %>%
select(sentiment, n) %>%
distinct(sentiment, .keep_all = TRUE) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment=(positive-negative), method='Bing et al.', Date=date[j])
s_score_a[[j]] <- tidy_MPR %>%
inner_join(get_sentiments('afinn'), by="word") %>%
summarise(sentiment = sum(value)/n()) %>%
mutate(method = "AFINN", Date = date[j])
}
# Dates for downloaded files
files <- list.files(pattern = "^mpr")
date  <- as.Date(substr(files,5,14))
mths  <- month.abb[month(date)]
yrs   <- year(date)
s_score_fed <- list()
s_score_a   <- list()
s_score_b   <- list()
pts     <- list()
igram   <- list()
for(j in 1:length(files)) {
MPR <- text_to_frame(files[[j]]) # %>%
# mmutate(text = gsub("[[:punct:]]+", " ", text))
# Unnest tokens to single words
tidy_MPR <- MPR %>%
unnest_tokens(word, text) %>%
anti_join(stop_words, by="word")
# Count 'inflation'
igram[[j]] <- tidy_MPR %>%
summarise(pi = 100*sum(word == "inflation")/n()) %>%
mutate(Date = date[j])
# Popular word plots
pts[[j]] <- tidy_MPR %>%
mutate(word = wordStem(word)) %>%
count(word, sort=TRUE) %>%
mutate(proportion = n/sum(n)) %>%
filter(proportion > 0.01) %>%     # More than 1% of the words
mutate(word = reorder(word,proportion)) %>%
ggplot(aes(word,proportion)) +
geom_col(aes(fill=word), show.legend = FALSE) +
theme_minimal() +
coord_flip() +
theme(plot.title = element_text(size=10)) +
labs(title=paste0(mths[j], " ", yrs[j], ": count/total_words"), x="", y="")
# Sentiment scores
s_score_fed[[j]] <- tidy_MPR %>%
mutate(nwords = n()) %>%
inner_join(Sdict, by="word") %>%
add_count(Mood) %>%
mutate(n = n/nwords) %>%
select(Mood, n) %>%
distinct(Mood, .keep_all = TRUE) %>%
pivot_wider(names_from = Mood, values_from = n, values_fill = 0) %>%
mutate(sentiment=(Positive-Negative), method='FED', Date=date[j])
s_score_b[[j]] <- tidy_MPR %>%
mutate(nwords = n()) %>%
inner_join(get_sentiments('bing'), by="word") %>%
add_count(sentiment) %>%
mutate(n = n/nwords) %>%
select(sentiment, n) %>%
distinct(sentiment, .keep_all = TRUE) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment=(positive-negative), method='Bing et al.', Date=date[j])
s_score_a[[j]] <- tidy_MPR %>%
inner_join(get_sentiments('afinn'), by="word") %>%
summarise(sentiment = sum(value)/n()) %>%
mutate(method = "AFINN", Date = date[j])
}
download.file(paste("https://fred.stlouisfed.org/series/","/downloaddata/",".csv",
sep="CPALCY01CAQ661N"), destfile = "CACPI.csv")
Inflation <- read_csv("CACPI.csv") %>%
mutate(Inflation = 100*(VALUE/lag(VALUE,4) - 1)) %>%
filter(year(DATE) > 1994)
ggplot(bind_rows(igram)) +
geom_area(data=Inflation, aes(x=DATE, y=Inflation), fill="blue", color=NA, alpha=.3) +
geom_line(aes(x=Date, y=pi), color="red", size=.9) +
theme_minimal() +
labs(title="Canadian 'inflation' mentions (red) and inflation (blue)",
x="", y="% or % of words")
library(janeaustenr)
tidy_books <- austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number()) %>%
ungroup() %>%
unnest_tokens(word, text)
jane_austen_sentiment <- tidy_books %>%
inner_join(get_sentiments("bing"), by="word") %>%
count(book, index=linenumber %/% 80, sentiment) %>%  # Count group members
pivot_wider(names_from=sentiment, values_from=n, values_fill = 0) %>%
mutate(sentiment = positive - negative)
ggplot(jane_austen_sentiment, aes(index, sentiment, fill = book)) +
geom_col(show.legend = FALSE) +
theme_minimal() +
facet_wrap(~book, ncol = 2, scales = "free_x") +
labs(title="Jane Austen's books")
head(Sdict, 10)
adata <- bind_rows(s_score_b,s_score_a,s_score_fed)
all_s <- ggplot(adata) +
geom_col(aes(x=Date, y=sentiment, fill=method), show.legend = FALSE) +
theme_minimal() +
facet_wrap(~ method, ncol=1, scales='free_y') +
labs(title="Bank of Canada MPR: Sentiment scores", x="", y="")
plot(all_s)
install.packages("reticulate")
install.packages("shinydashboard")
install.packages("shinyjs", dependencies=TRUE)
install.packages("shinydashboard", dependencies=TRUE)
install.packages("shinydashboard")
install.packages("shinycssloaders")
install.packages("shinyBS")
install.packages("wordcloud")
install.packages("tm")
install.packages("textdata")
install.packages("ggraph")
install.packages("Hmisc")
install.packages("sentimentr")
install.packages(c("siebanxicor", "wesanderson"))
knitr::opts_chunk$set(echo = TRUE)
# install.packages("siebanxicor")
library("siebanxicor")
library("tidyverse")
library("RColorBrewer")
library(wesanderson)
token_file <- read.csv("../token/SIE_Token_Vic.csv", header=FALSE)
my_token <- token_file$V2[1]
setToken(my_token)
token_file <- read.csv("../token/SIE_Token_Vic.csv", header=FALSE)
my_token <- token_file$V2[1]
setToken(my_token)
token_file <- read.csv("../token/SIE_Token_Vic.csv", header=FALSE)
#my_token <- token_file$V2[1]
#setToken(my_token)
token_file <- read.csv("../token/SIE_Token_Vic.csv", header=FALSE)
token_file
#my_token <- token_file$V2[1]
#setToken(my_token)
token_file <- read.csv("../token/SIE_Token_Vic.csv", header=FALSE)
token_file
my_token <- token_file$V2[1]
#setToken(my_token)
token_file <- read.csv("../token/SIE_Token_Vic.csv", header=FALSE)
my_token <- token_file$V2[1]
my_token
#setToken(my_token)
token_file <- read.csv("../token/SIE_Token_Vic.csv", header=FALSE)
my_token <- token_file$V2
my_token
#setToken(my_token)
token_file <- read.csv("../token/SIE_Token_Vic.csv", header=FALSE)
#my_token <- token_file$V2
my_token
#setToken(my_token)
token_file <- read.csv("../token/SIE_Token_Vic.csv", header=FALSE)
#my_token <- token_file$V2
token_file
#setToken(my_token)
token_file <- read_csv("../token/SIE_Token_Vic.csv", header=FALSE)
token_file <- read_csv("../token/SIE_Token_Vic.csv")
#my_token <- token_file$V2
token_file
#setToken(my_token)
token_file <- read_csv("../token/SIE_Token_Vic.csv")
#my_token <- token_file$V2
token_file
#setToken(my_token)
token_file <- read.csv("../token/SIE_Token_Vic.csv", header=FALSE)
#my_token <- token_file$V2
token_file
#setToken(my_token)
token_file <- read.csv("../token/SIE_Token_Vic.csv", header=FALSE, sep=";")
#my_token <- token_file$V2
token_file
#setToken(my_token)
token_file <- read.csv("../token/SIE_Token_Vic.csv", header=FALSE, sep=";")
#my_token <- token_file$V2
token_file
#setToken(my_token)
token_file <- read.csv("../token/SIE_Token_Vic.csv", header=FALSE, sep=";")
#my_token <- token_file$V2
token_file
#setToken(my_token)
token_file <- read.csv("../token/SIE_Token_Vic.csv", header=FALSE, sep=";")
#my_token <- token_file$V2
token_file
#setToken(my_token)
token_file <- read.csv("../token/SIE_Token_Vic.csv", header=FALSE, sep=",")
#my_token <- token_file$V2
token_file
#setToken(my_token)
token_file <- read.csv("../token/SIE_Token_Vic.csv", header=FALSE, sep=",")
#my_token <- token_file$V2
token_file
#setToken(my_token)
token_file <- read.csv("../token/SIE_Token_Vic.csv", header=FALSE)
#my_token <- token_file$V2
token_file
#setToken(my_token)
shiny::runApp('Documents/levic/Projects_git/SIE_API_guide/sie_cash_app')
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
